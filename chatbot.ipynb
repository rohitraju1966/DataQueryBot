{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03113ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from glob import glob\n",
    "import csv\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b1aa9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quote_json_fields(input_path, output_path):\n",
    "    with open(input_path, \"r\", newline='', encoding='utf-8') as infile, \\\n",
    "         open(output_path, \"w\", newline='', encoding='utf-8') as outfile:\n",
    "        \n",
    "        reader = csv.reader(infile)\n",
    "        writer = csv.writer(outfile, quoting=csv.QUOTE_MINIMAL)\n",
    "        \n",
    "        for row in reader:\n",
    "            new_row = []\n",
    "            for cell in row:\n",
    "                stripped = cell.strip()\n",
    "                if stripped.startswith(\"{\") and stripped.endswith(\"}\"):\n",
    "                    # Wrap in quotes if not already quoted\n",
    "                    cell = f'\"{stripped}\"' if not (stripped.startswith('\"') and stripped.endswith('\"')) else cell\n",
    "                new_row.append(cell)\n",
    "            writer.writerow(new_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "917e948d",
   "metadata": {},
   "outputs": [],
   "source": [
    "quote_json_fields(\"Data/orders_2025_3.csv\", \"orders_2025_3_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad53fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: stores_2025_4.csv → Processed/fixed_stores_2025_4.csv\n",
      "Processed: stores_2025_2.csv → Processed/fixed_stores_2025_2.csv\n",
      "Processed: stores_2025_3.csv → Processed/fixed_stores_2025_3.csv\n",
      "Processed: stores_2025_1.csv → Processed/fixed_stores_2025_1.csv\n",
      "Processed: stores_2024_10.csv → Processed/fixed_stores_2024_10.csv\n",
      "Processed: customers_2025_3.csv → Processed/fixed_customers_2025_3.csv\n",
      "Processed: customers_2025_2.csv → Processed/fixed_customers_2025_2.csv\n",
      "Processed: stores_2024_11.csv → Processed/fixed_stores_2024_11.csv\n",
      "Processed: orders_2025_4.csv → Processed/fixed_orders_2025_4.csv\n",
      "Processed: stores_2024_12.csv → Processed/fixed_stores_2024_12.csv\n",
      "Processed: customers_2025_4.csv → Processed/fixed_customers_2025_4.csv\n",
      "Processed: orders_2025_3.csv → Processed/fixed_orders_2025_3.csv\n",
      "Processed: stores.csv → Processed/fixed_stores.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "#Replace commas inside nested JSON-like {...} structures with semicolons.\n",
    "def replace_commas_in_json_fields(line: str) -> str:\n",
    "    output = \"\"\n",
    "    buffer = \"\"\n",
    "    stack = 0\n",
    "    inside_json = False\n",
    "\n",
    "    for ch in line:\n",
    "        if ch == '{':\n",
    "            stack += 1\n",
    "            inside_json = True\n",
    "            buffer += ch\n",
    "        elif ch == '}':\n",
    "            stack -= 1\n",
    "            buffer += ch\n",
    "            if stack == 0:\n",
    "                inside_json = False\n",
    "                output += buffer.replace(\",\", \";\")\n",
    "                buffer = \"\"\n",
    "        elif inside_json:\n",
    "            buffer += ch\n",
    "        else:\n",
    "            output += ch\n",
    "\n",
    "    # Append any remaining buffer (in case of malformed JSON)\n",
    "    output += buffer\n",
    "    return output\n",
    "\n",
    "# Folder containing your files\n",
    "input_folder = \"Raw\"\n",
    "\n",
    "# Get all relevant CSV files\n",
    "all_csvs = glob(os.path.join(input_folder, \"*.csv\"))\n",
    "\n",
    "# Output folder for fixed versions\n",
    "output_folder = \"Processed\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "for csv_file in all_csvs:\n",
    "    file_name = os.path.basename(csv_file)\n",
    "    output_path = os.path.join(output_folder, f\"fixed_{file_name}\")\n",
    "\n",
    "    with open(csv_file, \"r\", encoding=\"utf-8\") as infile, \\\n",
    "         open(output_path, \"w\", encoding=\"utf-8\") as outfile:\n",
    "        \n",
    "        for line in infile:\n",
    "            fixed_line = replace_commas_in_json_fields(line)\n",
    "            outfile.write(fixed_line)\n",
    "\n",
    "    print(f\"Processed: {file_name} → {output_path}\")\n",
    "\n",
    "\n",
    "\n",
    "# Directory containing the fixed files\n",
    "fixed_folder = \"Processed\"\n",
    "\n",
    "# Define JSON-like columns that were semicolon-patched\n",
    "orders_json_cols = [\"delivery_info\", \"subscription_discounts_metadata\"]\n",
    "stores_json_cols = [\"platform_fee\", \"delivery_fee\", \"pre_sale\", \"consumer_fee\"]\n",
    "customers_json_cols = []  \n",
    "\n",
    "def load_and_restore_commas(files, json_columns):\n",
    "    dfs = []\n",
    "    for file in files:\n",
    "        try:\n",
    "            df = pd.read_csv(file, dtype=str)\n",
    "            for col in json_columns:\n",
    "                if col in df.columns:\n",
    "                    df[col] = df[col].str.replace(\";\", \",\", regex=False)\n",
    "            dfs.append(df)\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {file}: {e}\")\n",
    "    if dfs:\n",
    "        return pd.concat(dfs, ignore_index=True).drop_duplicates()\n",
    "    return pd.DataFrame()\n",
    "\n",
    "# File collection\n",
    "orders_files = glob(os.path.join(fixed_folder, \"fixed_orders_*.csv\"))\n",
    "customers_files = glob(os.path.join(fixed_folder, \"fixed_customers_*.csv\"))\n",
    "stores_files = glob(os.path.join(fixed_folder, \"fixed_stores_*.csv\")) + [os.path.join(fixed_folder, \"fixed_stores.csv\")]\n",
    "\n",
    "# Load, repair, and concat\n",
    "orders_df = load_and_restore_commas(orders_files, orders_json_cols)\n",
    "customers_df = load_and_restore_commas(customers_files, customers_json_cols)\n",
    "stores_df = load_and_restore_commas(stores_files, stores_json_cols)\n",
    "\n",
    "\n",
    "orders_df.loc[\n",
    "    (\n",
    "        orders_df['fulfillment_type'].isin(['pickup', 'curbside']) |\n",
    "        (orders_df['order_type'].isin(['store_credit_reload', 'gift_card', 'subscription_purchase']))\n",
    "    ) & orders_df['delivery_fee_in_cents'].isna(),\n",
    "    'delivery_fee_in_cents'\n",
    "] = 0\n",
    "\n",
    "# Fill JSON-like fields with empty objects\n",
    "orders_df['subscription_discounts_metadata'] = orders_df['subscription_discounts_metadata'].fillna('{}')\n",
    "orders_df['delivery_info'] = orders_df['delivery_info'].fillna('{}')\n",
    "\n",
    "# Fill notes with empty string\n",
    "orders_df['notes'] = orders_df['notes'].fillna('')\n",
    "\n",
    "# Fill scheduled_fulfillment_at with a fallback timestamp (using created_at)\n",
    "orders_df['scheduled_fulfillment_at'] = orders_df['scheduled_fulfillment_at'].fillna(orders_df['created_at'])\n",
    "\n",
    "# Clean stores database missing values that are JSON-like fields with empty objects\n",
    "stores_df['platform_fee'] = stores_df['platform_fee'].fillna('{}')\n",
    "stores_df['consumer_fee'] = stores_df['consumer_fee'].fillna('{}')\n",
    "\n",
    "# Save cleaned outputs\n",
    "orders_df.to_csv(\"Processed/cleaned_orders.csv\", index=False)\n",
    "customers_df.to_csv(\"Processed/cleaned_customers.csv\", index=False)\n",
    "stores_df.to_csv(\"Processed/cleaned_stores.csv\", index=False)\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import os\n",
    "\n",
    "# Load Cleaned CSVs\n",
    "processed_folder = \"Processed\"\n",
    "orders_csv = os.path.join(processed_folder, \"cleaned_orders.csv\")\n",
    "customers_csv = os.path.join(processed_folder, \"cleaned_customers.csv\")\n",
    "stores_csv = os.path.join(processed_folder, \"cleaned_stores.csv\")\n",
    "\n",
    "orders_df = pd.read_csv(orders_csv)\n",
    "customers_df = pd.read_csv(customers_csv)\n",
    "stores_df = pd.read_csv(stores_csv)\n",
    "\n",
    "# Create SQLite DB\n",
    "db_path = os.path.join(processed_folder, \"dashboard_chatbot.db\")\n",
    "conn = sqlite3.connect(db_path)\n",
    "\n",
    "# Load DataFrames into SQLite Tables \n",
    "orders_df.to_sql(\"orders\", conn, if_exists=\"replace\", index=False)\n",
    "customers_df.to_sql(\"customers\", conn, if_exists=\"replace\", index=False)\n",
    "stores_df.to_sql(\"stores\", conn, if_exists=\"replace\", index=False)\n",
    "\n",
    "conn.close()\n",
    "\n",
    "print(f\"Loaded all tables into {db_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "81c88985",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>march_revenue</th>\n",
       "      <th>april_revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>78020.08</td>\n",
       "      <td>76174.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   march_revenue  april_revenue\n",
       "0       78020.08       76174.88"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sqlite3\n",
    "conn = sqlite3.connect(db_path)\n",
    "query = f\"\"\"\n",
    "SELECT\n",
    "  ROUND(\n",
    "    SUM(\n",
    "      CASE\n",
    "        WHEN DATE(o.created_at) BETWEEN '2025-03-01' AND '2025-03-31'\n",
    "        THEN o.total_amount_in_cents\n",
    "        ELSE 0\n",
    "      END\n",
    "    ) / 100.0,\n",
    "    2\n",
    "  ) AS march_revenue,\n",
    "  ROUND(\n",
    "    SUM(\n",
    "      CASE\n",
    "        WHEN DATE(o.created_at) BETWEEN '2025-04-01' AND '2025-04-30'\n",
    "        THEN o.total_amount_in_cents\n",
    "        ELSE 0\n",
    "      END\n",
    "    ) / 100.0,\n",
    "    2\n",
    "  ) AS april_revenue\n",
    "FROM orders AS o\n",
    "JOIN stores AS s ON o.store_id = s.store_id\n",
    "WHERE s.name = 'Tikka Shack';\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_sql_query(query, conn)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "fb304d27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store_id</th>\n",
       "      <th>external_store_id</th>\n",
       "      <th>name</th>\n",
       "      <th>active</th>\n",
       "      <th>created_at</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>delivery_fee</th>\n",
       "      <th>platform_fee</th>\n",
       "      <th>consumer_fee</th>\n",
       "      <th>pre_sale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>b93662c5-860a-45dd-9e15-c35611fc9b17</td>\n",
       "      <td>MLT2B1R9E1RQC</td>\n",
       "      <td>Frank Coffee</td>\n",
       "      <td>True</td>\n",
       "      <td>2024-04-29T21:01:12.103Z</td>\n",
       "      <td>2025-04-15T14:16:58.198Z</td>\n",
       "      <td>{\"fee\":0,\"title\":null,\"waiver\":0,\"enabled_fee\"...</td>\n",
       "      <td>{\"fee\":25,\"type\":\"amount\",\"enabled_fee\":true,\"...</td>\n",
       "      <td>{\"pickup\":{\"type\":\"amount\",\"enabled_fee\":false...</td>\n",
       "      <td>{\"active\":false}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 store_id external_store_id          name  \\\n",
       "371  b93662c5-860a-45dd-9e15-c35611fc9b17     MLT2B1R9E1RQC  Frank Coffee   \n",
       "\n",
       "     active                created_at                updated_at  \\\n",
       "371    True  2024-04-29T21:01:12.103Z  2025-04-15T14:16:58.198Z   \n",
       "\n",
       "                                          delivery_fee  \\\n",
       "371  {\"fee\":0,\"title\":null,\"waiver\":0,\"enabled_fee\"...   \n",
       "\n",
       "                                          platform_fee  \\\n",
       "371  {\"fee\":25,\"type\":\"amount\",\"enabled_fee\":true,\"...   \n",
       "\n",
       "                                          consumer_fee           pre_sale  \n",
       "371  {\"pickup\":{\"type\":\"amount\",\"enabled_fee\":false...  {\"active\":false}   "
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stores_df[stores_df['store_id']=='b93662c5-860a-45dd-9e15-c35611fc9b17']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "1d0d9a99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer:\n",
      "| march_orders | april_orders | march_revenue | april_revenue |\n",
      "| --- | --- | --- | --- |\n",
      "| 2784 | 2809 | 78020.08 | 76174.88 |\n",
      "\n",
      "Tikka Shack received 25 more orders in April 2025 compared to March 2025, but the revenue decreased by $1845.20. Consider offering a limited-time discount or promotion to boost sales and revenue in the upcoming months.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "from groq import Groq\n",
    "\n",
    "SCHEMA_DESCRIPTION = \"\"\"\n",
    "(Note: Text in parentheses indicates “column_name (TYPE, brief‐description)”)\n",
    "\n",
    "Use **SQLite** syntax only. Do not use any MySQL‐specific functions\n",
    "such as `DATE_SUB`, `CURDATE()`, or `DATE_FORMAT`. Instead, use\n",
    "`DATE('now', '-X days')`, `DATE('now')`, `strftime(…)`, etc.\n",
    "\n",
    "Tables:\n",
    "orders(\n",
    "    order_id (UUID, primary key),\n",
    "    store_id (UUID, foreign key → stores.store_id),\n",
    "    customer_id (UUID, foreign key → customers.customer_id),\n",
    "    external_location_id (STRING, external system’s location identifier),\n",
    "    external_order_id (STRING, external system’s order identifier),\n",
    "    total_amount_in_cents (INTEGER, total order value),\n",
    "    discount_amount_in_cents (INTEGER, discount applied),\n",
    "    delivery_fee_in_cents (INTEGER, fee charged for delivery),\n",
    "    created_at (DATETIME, order creation timestamp),\n",
    "    updated_at (DATETIME, last update timestamp),\n",
    "    fulfillment_type (ENUM: “pickup”|“delivery”|“curbside”),\n",
    "    tip_amount_in_cents (INTEGER, tip given by customer),\n",
    "    service_fee_in_cents (INTEGER, platform service fee),\n",
    "    subscription_discounts_metadata (JSON, subscription discount details),\n",
    "    notes (STRING, free‐text notes on order),\n",
    "    delivery_info (JSON, delivery details like addresses/times),\n",
    "    risk_level (INTEGER, fraud risk score: 0 = low, 1 = high),\n",
    "    order_type (ENUM: “regular_checkout”|“store_credit_reload”|“gift_card”|“subscription_purchase”),\n",
    "    perdiem_platform_fee_in_cents (INTEGER, PerDiem’s platform fee),\n",
    "    scheduled_fulfillment_at (DATETIME, scheduled pickup/delivery time)\n",
    ")\n",
    "customers(\n",
    "    customer_id (UUID, primary key),\n",
    "    store_id (UUID, foreign key → stores.store_id),\n",
    "    external_customer_id (STRING, external system’s customer ID)\n",
    ")\n",
    "stores(\n",
    "    store_id (UUID, primary key),\n",
    "    external_store_id (STRING, external system’s store ID),\n",
    "    name (STRING, store name),\n",
    "    active (BOOLEAN, store status),\n",
    "    created_at (DATETIME, store record creation),\n",
    "    updated_at (DATETIME, store record last update),\n",
    "    delivery_fee (JSON, store’s base delivery fee settings),\n",
    "    platform_fee (JSON, store’s platform fee settings),\n",
    "    consumer_fee (JSON, consumer‐facing fees),\n",
    "    pre_sale (JSON, whether scheduled orders are allowed)\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "FEW_SHOT_SQL_PROMPT = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": (\n",
    "            f\"{SCHEMA_DESCRIPTION}\\n\"\n",
    "            \"Convert the user’s natural language request into a valid SQL query for this schema. \"\n",
    "            \"**Using SQLite syntax only.** Return only one SQL statement (no extra commentary).\"\n",
    "        )\n",
    "    },\n",
    "    # Example 1: Compare week1 vs week2 for a store by name\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Compare the number of orders between March 1–7 and March 8–14, 2025 for store 'Migos Fine Foods'.\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": (\n",
    "            \"SELECT\\n\"\n",
    "            \"  SUM(CASE WHEN DATE(o.created_at) BETWEEN '2025-03-01' AND '2025-03-07' THEN 1 ELSE 0 END) AS week1_count,\\n\"\n",
    "            \"  SUM(CASE WHEN DATE(o.created_at) BETWEEN '2025-03-08' AND '2025-03-14' THEN 1 ELSE 0 END) AS week2_count\\n\"\n",
    "            \"FROM orders AS o\\n\"\n",
    "            \"JOIN stores AS s ON o.store_id = s.store_id\\n\"\n",
    "            \"WHERE s.name = 'Migos Fine Foods';\"\n",
    "        )\n",
    "    },\n",
    "    # Example 2: Total revenue for a store by name in Q1 2025\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Total revenue (in dollars) for 'Migos Fine Foods' from January 1 to March 31, 2025?\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": (\n",
    "            \"SELECT\\n\"\n",
    "            \"  ROUND(SUM(o.total_amount_in_cents) / 100.0, 2) AS total_revenue\\n\"\n",
    "            \"FROM orders AS o\\n\"\n",
    "            \"JOIN stores AS s ON o.store_id = s.store_id\\n\"\n",
    "            \"WHERE s.name = 'Migos Fine Foods'\\n\"\n",
    "            \"  AND DATE(o.created_at) BETWEEN '2025-01-01' AND '2025-03-31';\"\n",
    "        )\n",
    "    },\n",
    "    # Example 3: Count pickup orders for a specific week\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"How many pickup orders did 'Migos Fine Foods' have between March 15 and March 21, 2025?\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": (\n",
    "            \"SELECT\\n\"\n",
    "            \"  COUNT(*) AS pickup_orders_week\\n\"\n",
    "            \"FROM orders AS o\\n\"\n",
    "            \"JOIN stores AS s ON o.store_id = s.store_id\\n\"\n",
    "            \"WHERE s.name = 'Migos Fine Foods'\\n\"\n",
    "            \"  AND o.fulfillment_type = 'pickup'\\n\"\n",
    "            \"  AND DATE(o.created_at) BETWEEN '2025-03-15' AND '2025-03-21';\"\n",
    "        )\n",
    "    }\n",
    "]\n",
    "\n",
    "api_key = os.getenv(\"GROQ_KEY\")\n",
    "client = Groq(api_key=api_key)\n",
    "\n",
    "def nl_to_sql(query: str) -> str:\n",
    "    messages = FEW_SHOT_SQL_PROMPT + [{\"role\": \"user\", \"content\": query}]\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"llama3-70b-8192\",\n",
    "        messages=messages,\n",
    "        temperature=0.0,\n",
    "        max_tokens=256\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "def fix_sql_with_error(question: str, bad_sql: str, error_msg: str) -> str:\n",
    "    fix_prompt = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": (\n",
    "                f\"{SCHEMA_DESCRIPTION}\\n\"\n",
    "                \"One of your previously generated SQL statements failed on SQLite with an error. \"\n",
    "                \"Below is the user’s original question, the SQL you provided, and the SQLite error message. \"\n",
    "                \"Please correct the SQL to be valid SQLite syntax and satisfy the original request. \"\n",
    "                \"Return only the corrected SQL statement (no commentary).\"\n",
    "            )\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": (\n",
    "                f\"User question: {question}\\n\"\n",
    "                f\"Bad SQL: {bad_sql}\\n\"\n",
    "                f\"SQLite error: {error_msg}\"\n",
    "            )\n",
    "        }\n",
    "    ]\n",
    "    #print(fix_prompt)\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"llama3-70b-8192\",\n",
    "        messages=fix_prompt,\n",
    "        temperature=0.0,\n",
    "        max_tokens=256\n",
    "    )\n",
    "    #print(response.choices[0].message)\n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "\n",
    "FEW_SHOT_SUMMARY_PROMPT = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": (\n",
    "            \"You are given:\\n\"\n",
    "            \"• The user’s original question\\n\"\n",
    "            \"• The final SQL query that was executed\\n\"\n",
    "            \"• The resulting table (or an error message)\\n\\n\"\n",
    "            \"Instructions:\\n\"\n",
    "            \"1. If the result has multiple rows, include a small markdown‐style table showing those rows.  \\n\"\n",
    "            \"2. Immediately below, draw one or two brief insights with precise numbers.  \\n\"\n",
    "            \"3. If the insights suggest an opportunity (e.g., a drop in pickup orders, or one store vastly outperforming others), then propose a specific marketing promotion.  \\n\"\n",
    "            \"4. Otherwise, skip any marketing suggestion.  \\n\"\n",
    "            \"5. Always use only the rows shown—do not add, infer, or omit values.  \\n\"\n",
    "            \"6. If there is an error or no rows, reply exactly:\\n\"\n",
    "            \"   “I’m sorry, I couldn’t retrieve an answer—please rephrase or check the data.”  \\n\"\n",
    "            \"7. If the single row is 0, reply exactly:\\n\"\n",
    "            \"   “It seems there are zero matching records—please verify your question.”  \\n\"\n",
    "            \"8. Otherwise, for a single non‐zero row, answer in one sentence (no table needed) and only add a marketing idea if it follows logically from the insight.\"\n",
    "        )\n",
    "    },\n",
    "    # ---- FEW-SHOT EXAMPLE 1 ----\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"User question: How many months data of orders do I have? and what are those months?\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"There are two months with order data: 2025-03 and 2025-04. So the user has data for March 2025 and April 2025.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "def summarize_result(question: str, sql_query: str, df: pd.DataFrame = None, error_msg: str = None) -> str:\n",
    "    \"\"\"\n",
    "    Summarize the SQL result (or error) in plain language.\n",
    "    - If error_msg is provided: ask the user to rephrase.\n",
    "    - If df exists but all values are zero or empty: ask to verify data.\n",
    "    - Otherwise: summarize the DataFrame’s contents.\n",
    "    \"\"\"\n",
    "    # Build the “results” part of the prompt\n",
    "    if error_msg:\n",
    "        result_content = f\"Error executing SQL: {error_msg}\"\n",
    "    elif df is None or df.empty:\n",
    "        result_content = \"Result: no rows returned.\"\n",
    "    else:\n",
    "        # Convert small DataFrame to markdown‐style table text\n",
    "        table_text = df.to_csv(index=False)\n",
    "        # Check if single value 0\n",
    "        if df.shape == (1, 1) and str(df.iat[0, 0]) in (\"0\", \"0.0\"):\n",
    "            result_content = \"Result: single value 0\"\n",
    "        else:\n",
    "            result_content = f\"Result Table:\\n{table_text}\"\n",
    "\n",
    "    messages = FEW_SHOT_SUMMARY_PROMPT + [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": (\n",
    "            f\"User question: {question}\\n\"\n",
    "            f\"SQL Query: {sql_query}\\n\"\n",
    "            f\"{result_content}\"\n",
    "        )\n",
    "    }\n",
    "   ]\n",
    "    \n",
    "   #print(messages)\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"llama3-70b-8192\",\n",
    "        messages=messages,\n",
    "        temperature=0.0,\n",
    "        max_tokens=256\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Natural language question\n",
    "    user_question = (\n",
    "        \"How did Tikka Shack perform in march 2025 in comparison to april 2025\"\n",
    "    )\n",
    "    \n",
    "    generated_sql = nl_to_sql(user_question)\n",
    "    #print(\"Initial Generated SQL:\")\n",
    "    #print(generated_sql)\n",
    "\n",
    "    db_path = \"Processed/dashboard_chatbot.db\"\n",
    "    engine = create_engine(f\"sqlite:///{db_path}\")\n",
    "\n",
    "    try:\n",
    "        df_result = pd.read_sql_query(generated_sql, engine)\n",
    "        #print(\"\\nQuery Result:\")\n",
    "        #print(df_result)\n",
    "        error_msg = None\n",
    "\n",
    "    except Exception as e:\n",
    "        error_msg = str(e)\n",
    "        #print(f\"\\nError executing SQL:\\n{error_msg}\")\n",
    "        corrected_sql = fix_sql_with_error(user_question, generated_sql, error_msg)\n",
    "        #print(\"\\nCorrected SQL:\")\n",
    "        #print(corrected_sql)\n",
    "        try:\n",
    "            df_result = pd.read_sql_query(corrected_sql, engine)\n",
    "            #print(\"\\nFixed Query Result:\")\n",
    "            #print(df_result)\n",
    "            error_msg = None\n",
    "        except Exception as e2:\n",
    "            error_msg = str(e)\n",
    "            df_result = None\n",
    "            print(f\"\\nStill failing after correction: {e2}\")\n",
    "            \n",
    "    \n",
    "    summary = summarize_result(user_question, generated_sql, df_result, error_msg)\n",
    "    print(\"\\nAnswer:\")\n",
    "    print(summary)\n",
    "            \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a247b884",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "from groq import Groq\n",
    "\n",
    "# 1) Import ConversationBufferMemory from LangChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "SCHEMA_DESCRIPTION = \"\"\"\n",
    "(Note: Text in parentheses indicates “column_name (TYPE, brief‐description)”)\n",
    "\n",
    "Use **SQLite** syntax only. Do not use any MySQL‐specific functions\n",
    "such as `DATE_SUB`, `CURDATE()`, or `DATE_FORMAT`. Instead, use\n",
    "`DATE('now', '-X days')`, `DATE('now')`, `strftime(…)`, etc.\n",
    "\n",
    "Tables:\n",
    "orders(\n",
    "    order_id (UUID, primary key),\n",
    "    store_id (UUID, foreign key → stores.store_id),\n",
    "    customer_id (UUID, foreign key → customers.customer_id),\n",
    "    external_location_id (STRING, external system’s location identifier),\n",
    "    external_order_id (STRING, external system’s order identifier),\n",
    "    total_amount_in_cents (INTEGER, total order value),\n",
    "    discount_amount_in_cents (INTEGER, discount applied),\n",
    "    delivery_fee_in_cents (INTEGER, fee charged for delivery),\n",
    "    created_at (DATETIME, order creation timestamp),\n",
    "    updated_at (DATETIME, last update timestamp),\n",
    "    fulfillment_type (ENUM: “pickup”|“delivery”|“curbside”),\n",
    "    tip_amount_in_cents (INTEGER, tip given by customer),\n",
    "    service_fee_in_cents (INTEGER, platform service fee),\n",
    "    subscription_discounts_metadata (JSON, subscription discount details),\n",
    "    notes (STRING, free‐text notes on order),\n",
    "    delivery_info (JSON, delivery details like addresses/times),\n",
    "    risk_level (INTEGER, fraud risk score: 0 = low, 1 = high),\n",
    "    order_type (ENUM: “regular_checkout”|“store_credit_reload”|“gift_card”|“subscription_purchase”),\n",
    "    perdiem_platform_fee_in_cents (INTEGER, PerDiem’s platform fee),\n",
    "    scheduled_fulfillment_at (DATETIME, scheduled pickup/delivery time)\n",
    ")\n",
    "customers(\n",
    "    customer_id (UUID, primary key),\n",
    "    store_id (UUID, foreign key → stores.store_id),\n",
    "    external_customer_id (STRING, external system’s customer ID)\n",
    ")\n",
    "stores(\n",
    "    store_id (UUID, primary key),\n",
    "    external_store_id (STRING, external system’s store ID),\n",
    "    name (STRING, store name),\n",
    "    active (BOOLEAN, store status),\n",
    "    created_at (DATETIME, store record creation),\n",
    "    updated_at (DATETIME, store record last update),\n",
    "    delivery_fee (JSON, store’s base delivery fee settings),\n",
    "    platform_fee (JSON, store’s platform fee settings),\n",
    "    consumer_fee (JSON, consumer‐facing fees),\n",
    "    pre_sale (JSON, whether scheduled orders are allowed)\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "FEW_SHOT_SQL_PROMPT = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": (\n",
    "            f\"{SCHEMA_DESCRIPTION}\\n\"\n",
    "            \"Convert the user’s natural language request into a valid SQL query for this schema. \"\n",
    "            \"**Using SQLite syntax only.** Return only one SQL statement (no extra commentary).\"\n",
    "        )\n",
    "    },\n",
    "    # Example 1: Compare week1 vs week2 for a store by name\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Compare the number of orders between March 1–7 and March 8–14, 2025 for store 'Migos Fine Foods'.\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": (\n",
    "            \"SELECT\\n\"\n",
    "            \"  SUM(CASE WHEN DATE(o.created_at) BETWEEN '2025-03-01' AND '2025-03-07' THEN 1 ELSE 0 END) AS week1_count,\\n\"\n",
    "            \"  SUM(CASE WHEN DATE(o.created_at) BETWEEN '2025-03-08' AND '2025-03-14' THEN 1 ELSE 0 END) AS week2_count\\n\"\n",
    "            \"FROM orders AS o\\n\"\n",
    "            \"JOIN stores AS s ON o.store_id = s.store_id\\n\"\n",
    "            \"WHERE s.name = 'Migos Fine Foods';\"\n",
    "        )\n",
    "    },\n",
    "    # Example 2: Total revenue for a store by name in Q1 2025\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Total revenue (in dollars) for 'Migos Fine Foods' from January 1 to March 31, 2025?\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": (\n",
    "            \"SELECT\\n\"\n",
    "            \"  ROUND(SUM(o.total_amount_in_cents) / 100.0, 2) AS total_revenue\\n\"\n",
    "            \"FROM orders AS o\\n\"\n",
    "            \"JOIN stores AS s ON o.store_id = s.store_id\\n\"\n",
    "            \"WHERE s.name = 'Migos Fine Foods'\\n\"\n",
    "            \"  AND DATE(o.created_at) BETWEEN '2025-01-01' AND '2025-03-31';\"\n",
    "        )\n",
    "    },\n",
    "    # Example 3: Count pickup orders for a specific week\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"How many pickup orders did 'Migos Fine Foods' have between March 15 and March 21, 2025?\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": (\n",
    "            \"SELECT\\n\"\n",
    "            \"  COUNT(*) AS pickup_orders_week\\n\"\n",
    "            \"FROM orders AS o\\n\"\n",
    "            \"JOIN stores AS s ON o.store_id = s.store_id\\n\"\n",
    "            \"WHERE s.name = 'Migos Fine Foods'\\n\"\n",
    "            \"  AND o.fulfillment_type = 'pickup'\\n\"\n",
    "            \"  AND DATE(o.created_at) BETWEEN '2025-03-15' AND '2025-03-21';\"\n",
    "        )\n",
    "    }\n",
    "]\n",
    "\n",
    "api_key = os.getenv(\"GROQ_KEY\")\n",
    "client = Groq(api_key=api_key)\n",
    "\n",
    "def nl_to_sql(query: str) -> str:\n",
    "    messages = FEW_SHOT_SQL_PROMPT + [{\"role\": \"user\", \"content\": query}]\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"llama3-70b-8192\",\n",
    "        messages=messages,\n",
    "        temperature=0.0,\n",
    "        max_tokens=256\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "def fix_sql_with_error(question: str, bad_sql: str, error_msg: str) -> str:\n",
    "    fix_prompt = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": (\n",
    "                f\"{SCHEMA_DESCRIPTION}\\n\"\n",
    "                \"One of your previously generated SQL statements failed on SQLite with an error. \"\n",
    "                \"Below is the user’s original question, the SQL you provided, and the SQLite error message. \"\n",
    "                \"Please correct the SQL to be valid SQLite syntax and satisfy the original request. \"\n",
    "                \"Return only the corrected SQL statement (no commentary).\"\n",
    "            )\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": (\n",
    "                f\"User question: {question}\\n\"\n",
    "                f\"Bad SQL: {bad_sql}\\n\"\n",
    "                f\"SQLite error: {error_msg}\"\n",
    "            )\n",
    "        }\n",
    "    ]\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"llama3-70b-8192\",\n",
    "        messages=fix_prompt,\n",
    "        temperature=0.0,\n",
    "        max_tokens=256\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "\n",
    "FEW_SHOT_SUMMARY_PROMPT = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": (\n",
    "            \"You are given:\\n\"\n",
    "            \"• The user’s original question\\n\"\n",
    "            \"• The final SQL query that was executed\\n\"\n",
    "            \"• The resulting table (or an error message)\\n\"\n",
    "            \"• The conversation memory so far\\n\\n\"\n",
    "            \"Instructions:\\n\"\n",
    "            \"1. Primarily use the SQL‐extracted table to draw your insights and answer the question.\\n\"\n",
    "            \"2. If relevant, incorporate any context from the conversation memory to clarify or enrich your analysis, but do not let memory override the concrete numbers in the table.\\n\"\n",
    "            \"3. If the result has multiple rows, include a small markdown‐style table showing those rows.\\n\"\n",
    "            \"4. Immediately below that table, draw one or two brief insights with precise numbers.\\n\"\n",
    "            \"5. If those insights suggest an opportunity (e.g., a drop in pickup orders, or one store vastly outperforming others), then propose a specific marketing promotion.\\n\"\n",
    "            \"6. Otherwise, skip any marketing suggestion.\\n\"\n",
    "            \"7. Always use only the rows shown—do not add, infer, or omit values.\\n\"\n",
    "            \"8. If there is an error or no rows, first consult the conversation memory to try to answer the question. If you still cannot provide an answer, reply exactly:\\n\"\n",
    "            \"   “I’m sorry, I couldn’t retrieve an answer—please rephrase or check the data.”\\n\"\n",
    "            \"9. If the single row is 0, reply exactly:\\n\"\n",
    "            \"   “It seems there are zero matching records—please verify your question.”\\n\"\n",
    "            \"10. Otherwise, for a single non‐zero row, answer in one sentence (no table needed) and only add a marketing idea if it follows logically from the insight.\"\n",
    "        )\n",
    "    },\n",
    "    # ---- FEW-SHOT EXAMPLE 1 ----\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"User question: How many months data of orders do I have? and what are those months?\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"There are two months with order data: 2025-03 and 2025-04. So the user has data for March 2025 and April 2025.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# 2) Instantiate a ConversationBufferMemory\n",
    "memory = ConversationBufferMemory(return_messages=True)\n",
    "\n",
    "\n",
    "def summarize_result(question: str, sql_query: str, df: pd.DataFrame = None, error_msg: str = None) -> str:\n",
    "    \"\"\"\n",
    "    Summarize the SQL result (or error) in plain language,\n",
    "    injecting memory history as one of the prompt fields, then store the new Q→A in memory.\n",
    "    \"\"\"\n",
    "    # Build the “results” part of the prompt\n",
    "    if error_msg:\n",
    "        result_content = f\"Error executing SQL: {error_msg}\"\n",
    "    elif df is None or df.empty:\n",
    "        result_content = \"Result: no rows returned.\"\n",
    "    else:\n",
    "        # Convert small DataFrame to markdown‐style table text\n",
    "        table_text = df.to_csv(index=False)\n",
    "        # Check if single value 0\n",
    "        if df.shape == (1, 1) and str(df.iat[0, 0]) in (\"0\", \"0.0\"):\n",
    "            result_content = \"Result: single value 0\"\n",
    "        else:\n",
    "            result_content = f\"Result Table:\\n{table_text}\"\n",
    "\n",
    "    # 3) Load memory history and include it in the summary prompt\n",
    "    history_str = memory.load_memory_variables({})[\"history\"]\n",
    "    \n",
    "    print(history_str)\n",
    "\n",
    "    # Construct the messages, injecting the memory as its own user‐role field\n",
    "    messages = FEW_SHOT_SUMMARY_PROMPT + [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": (\n",
    "                f\"Conversation memory so far: {history_str}\\n\"\n",
    "                f\"User question: {question}\\n\"\n",
    "                f\"SQL Query: {sql_query}\\n\"\n",
    "                f\"{result_content}\"\n",
    "            )\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"llama3-70b-8192\",\n",
    "        messages=messages,\n",
    "        temperature=0.0,\n",
    "        max_tokens=256\n",
    "    )\n",
    "    summary = response.choices[0].message.content.strip()\n",
    "\n",
    "    # 4) Save the new (user_question → summary) pair into memory\n",
    "    memory.save_context({\"user\": question}, {\"assistant\": summary})\n",
    "\n",
    "    return summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "32a46414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content='What can I do to improve the sales then?'), AIMessage(content=\"I'm sorry, I couldn't retrieve an answer—please rephrase or check the data.\"), HumanMessage(content='How was tikka shack sale during march 2025?'), AIMessage(content=\"| total_sales |\\n| --- |\\n| 78020.08 |\\n\\nTikka Shack's total sales in March 2025 were $78,020.08. Since the user previously asked about improving sales, a potential marketing promotion could be offering a limited-time discount or loyalty reward to customers who make repeat purchases at Tikka Shack.\"), HumanMessage(content='Compare march 2025 sales of tikka shack to april 2025'), AIMessage(content=\"| march_sales | april_sales |\\n| --- | --- |\\n| 2304.81 | 76174.88 |\\n\\nTikka Shack's sales in March 2025 were $2,304.81, and in April 2025, they were $76,174.88. \\n\\nA potential marketing promotion could be to continue or expand the successful strategies used in April, as the sales increased significantly.\"), HumanMessage(content='How did tikka shack perform during march 2025 in comaprison to april 2025'), AIMessage(content=\"| march_revenue | april_revenue |\\n| --- | --- |\\n| 78020.08 | 76174.88 |\\n\\nTikka Shack's sales in March 2025 were $78,020.08, and in April 2025, they were $76,174.88. \\n\\nA potential marketing promotion could be to analyze and understand what factors contributed to the slight decrease in sales from March to April, and adjust strategies accordingly.\"), HumanMessage(content='How did tikka shack perform during march 2025 in comaprison to april 2025'), AIMessage(content=\"| march_revenue | april_revenue |\\n| --- | --- |\\n| 78020.08 | 76174.88 |\\n\\nTikka Shack's sales in March 2025 were $78,020.08, and in April 2025, they were $76,174.88. A potential marketing promotion could be to analyze and understand what factors contributed to the slight decrease in sales from March to April, and adjust strategies accordingly.\"), HumanMessage(content='How did tikka shack perform during march 2025 in comaprison to april 2025 in terms of both orders and sales'), AIMessage(content='| period | orders_march | sales_march |\\n| --- | --- | --- |\\n| March 2025 | 2784 | 78020.08 |\\n| April 2025 | 2809 | 76174.88 |\\n\\nTikka Shack received 2784 orders in March 2025 and 2809 orders in April 2025, with a slight increase in orders. The sales in March 2025 were $78,020.08, and in April 2025, they were $76,174.88, with a slight decrease in sales. A potential marketing promotion could be to analyze and understand what factors contributed to the slight decrease in sales from March to April, and adjust strategies accordingly.')]\n",
      "\n",
      "Answer:\n",
      "Based on our previous conversations, here are some strategies that can be employed:\n",
      "\n",
      "1. **Limited-time Discount**: Offer a limited-time discount to customers who make repeat purchases at Tikka Shack, as previously suggested.\n",
      "2. **Analyze Sales Factors**: Analyze and understand what factors contributed to the slight decrease in sales from March to April, and adjust strategies accordingly.\n",
      "3. **Expand Successful Strategies**: Continue or expand the successful strategies used in April, as the sales increased significantly.\n",
      "\n",
      "These strategies are based on the insights gained from the previous conversations and can help improve sales at Tikka Shack.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Natural language question\n",
    "    user_question = \"Based on our previous conversations, suggest some strategies\"\n",
    "\n",
    "    generated_sql = nl_to_sql(user_question)\n",
    "\n",
    "    db_path = \"Processed/dashboard_chatbot.db\"\n",
    "    engine = create_engine(f\"sqlite:///{db_path}\")\n",
    "\n",
    "    try:\n",
    "        df_result = pd.read_sql_query(generated_sql, engine)\n",
    "        error_msg = None\n",
    "\n",
    "    except Exception as e:\n",
    "        error_msg = str(e)\n",
    "        corrected_sql = fix_sql_with_error(user_question, generated_sql, error_msg)\n",
    "        try:\n",
    "            df_result = pd.read_sql_query(corrected_sql, engine)\n",
    "            error_msg = None\n",
    "        except Exception as e2:\n",
    "            error_msg = str(e2)\n",
    "            df_result = None\n",
    "\n",
    "    summary = summarize_result(user_question, generated_sql, df_result, error_msg)\n",
    "    print(\"\\nAnswer:\")\n",
    "    print(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c1aa056c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coffee Dose revenue by month (in dollars):\n",
      "  month revenue_usd\n",
      "2025-03 $148,582.58\n",
      "2025-04 $158,123.60\n",
      "\n",
      "Revenue in March 2025: $148,582.58\n",
      "Revenue in April 2025: $158,123.60\n",
      "Difference (April – March): $9,541.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lb/q4hhzm1x21ddckmdtyxcjd_r0000gn/T/ipykernel_52603/2557282596.py:27: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
      "  coffee_orders[\"month\"] = coffee_orders[\"created_at\"].dt.to_period(\"M\").astype(str)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Load cleaned stores to get the store_id for “Coffee Dose”\n",
    "stores_df = pd.read_csv(\"Processed/cleaned_stores.csv\", dtype=str)\n",
    "coffee_dose_row = stores_df[stores_df[\"name\"] == \"Coffee Dose\"]\n",
    "\n",
    "if coffee_dose_row.empty:\n",
    "    raise ValueError(\"No store named 'Coffee Dose' found in cleaned_stores.csv\")\n",
    "\n",
    "coffee_dose_id = coffee_dose_row.iloc[0][\"store_id\"]\n",
    "\n",
    "# 2. Load cleaned orders and filter for Coffee Dose\n",
    "orders_df = pd.read_csv(\"Processed/cleaned_orders.csv\", dtype=str)\n",
    "\n",
    "# Convert total_amount_in_cents to integer (cents)\n",
    "orders_df[\"total_amount_in_cents\"] = (\n",
    "    pd.to_numeric(orders_df[\"total_amount_in_cents\"], errors=\"coerce\")\n",
    "      .fillna(0)\n",
    "      .astype(int)\n",
    ")\n",
    "\n",
    "# Filter orders for Coffee Dose by store_id\n",
    "coffee_orders = orders_df[orders_df[\"store_id\"] == coffee_dose_id].copy()\n",
    "\n",
    "# 3. Parse created_at to datetime and extract YYYY-MM as “month”\n",
    "coffee_orders[\"created_at\"] = pd.to_datetime(coffee_orders[\"created_at\"], errors=\"coerce\")\n",
    "coffee_orders[\"month\"] = coffee_orders[\"created_at\"].dt.to_period(\"M\").astype(str)\n",
    "\n",
    "# 4. Group by month and sum revenue (in cents), then convert to dollars\n",
    "monthly_revenue_cents = coffee_orders.groupby(\"month\")[\"total_amount_in_cents\"].sum()\n",
    "monthly_revenue_usd = monthly_revenue_cents / 100.0\n",
    "\n",
    "# 5. Display results and compute the difference between March 2025 and April 2025\n",
    "result_df = monthly_revenue_usd.reset_index().rename(\n",
    "    columns={\"total_amount_in_cents\": \"revenue_usd\", 0: \"revenue_usd\"}\n",
    ")\n",
    "result_df.columns = [\"month\", \"revenue_usd\"]\n",
    "print(\"Coffee Dose revenue by month (in dollars):\")\n",
    "print(result_df.to_string(index=False, formatters={\"revenue_usd\": \"${:,.2f}\".format}))\n",
    "\n",
    "# 6. Verify the change from March 2025 to April 2025\n",
    "revenue_march = monthly_revenue_usd.get(\"2025-03\", 0.0)\n",
    "revenue_april = monthly_revenue_usd.get(\"2025-04\", 0.0)\n",
    "difference = revenue_april - revenue_march\n",
    "\n",
    "print(f\"\\nRevenue in March 2025: ${revenue_march:,.2f}\")\n",
    "print(f\"Revenue in April 2025: ${revenue_april:,.2f}\")\n",
    "print(f\"Difference (April – March): ${difference:,.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8272312a",
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_df=pd.read_csv(\"/Users/rohit/Desktop/DataQueryBot/Processed/cleaned_orders.csv\")\n",
    "stores_df=pd.read_csv(\"/Users/rohit/Desktop/DataQueryBot/Processed/cleaned_stores.csv\")\n",
    "customers_df=pd.read_csv(\"/Users/rohit/Desktop/DataQueryBot/Processed/cleaned_customers.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e2e7199c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  fulfillment_type  total_revenue\n",
      "0         curbside           2.89\n",
      "1         delivery      115489.14\n",
      "2           pickup     1211278.06\n",
      "\n",
      "Highest‐revenue fulfillment type:\n",
      "  fulfillment_type  total_revenue\n",
      "2           pickup     1211278.06\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# (1) Ensure 'created_at' is datetime\n",
    "orders_df['created_at'] = pd.to_datetime(orders_df['created_at'], errors='coerce')\n",
    "\n",
    "# (2) Filter to Q1 2025\n",
    "mask_q1 = (\n",
    "    (orders_df['created_at'] >= '2025-01-01') &\n",
    "    (orders_df['created_at'] <  '2025-04-01')\n",
    ")\n",
    "q1 = orders_df[mask_q1].copy()\n",
    "\n",
    "# (3) Compute revenue in dollars\n",
    "q1['revenue'] = q1['total_amount_in_cents'].astype(int) / 100.0\n",
    "\n",
    "# (4) Group by fulfillment_type and sum\n",
    "rev_by_fulfillment = (\n",
    "    q1\n",
    "    .groupby('fulfillment_type')['revenue']\n",
    "    .sum()\n",
    "    .reset_index(name='total_revenue')\n",
    ")\n",
    "\n",
    "# (5) Identify max\n",
    "max_idx = rev_by_fulfillment['total_revenue'].idxmax()\n",
    "best_type = rev_by_fulfillment.loc[[max_idx]]\n",
    "print(rev_by_fulfillment)\n",
    "print(\"\\nHighest‐revenue fulfillment type:\")\n",
    "print(best_type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dea90ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "stores_df[stores_df['']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ba3d36bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables in database: ['orders', 'customers', 'stores']\n",
      "\n",
      "-- orders schema --\n",
      "    index                           column datatype  not_null default  \\\n",
      "0       0                         order_id     TEXT         0    None   \n",
      "1       1                         store_id     TEXT         0    None   \n",
      "2       2                      customer_id     TEXT         0    None   \n",
      "3       3             external_location_id     TEXT         0    None   \n",
      "4       4                external_order_id     TEXT         0    None   \n",
      "5       5            total_amount_in_cents     TEXT         0    None   \n",
      "6       6         discount_amount_in_cents     TEXT         0    None   \n",
      "7       7            delivery_fee_in_cents     TEXT         0    None   \n",
      "8       8                       created_at     TEXT         0    None   \n",
      "9       9                       updated_at     TEXT         0    None   \n",
      "10     10                 fulfillment_type     TEXT         0    None   \n",
      "11     11              tip_amount_in_cents     TEXT         0    None   \n",
      "12     12             service_fee_in_cents     TEXT         0    None   \n",
      "13     13  subscription_discounts_metadata     TEXT         0    None   \n",
      "14     14                            notes     TEXT         0    None   \n",
      "15     15                    delivery_info     TEXT         0    None   \n",
      "16     16                       risk_level     TEXT         0    None   \n",
      "17     17                       order_type     TEXT         0    None   \n",
      "18     18    perdiem_platform_fee_in_cents     TEXT         0    None   \n",
      "19     19         scheduled_fulfillment_at     TEXT         0    None   \n",
      "\n",
      "    primary_key  \n",
      "0             0  \n",
      "1             0  \n",
      "2             0  \n",
      "3             0  \n",
      "4             0  \n",
      "5             0  \n",
      "6             0  \n",
      "7             0  \n",
      "8             0  \n",
      "9             0  \n",
      "10            0  \n",
      "11            0  \n",
      "12            0  \n",
      "13            0  \n",
      "14            0  \n",
      "15            0  \n",
      "16            0  \n",
      "17            0  \n",
      "18            0  \n",
      "19            0  \n",
      "\n",
      "-- customers schema --\n",
      "   index                column datatype  not_null default  primary_key\n",
      "0      0           customer_id     TEXT         0    None            0\n",
      "1      1              store_id     TEXT         0    None            0\n",
      "2      2  external_customer_id     TEXT         0    None            0\n",
      "\n",
      "-- stores schema --\n",
      "   index             column datatype  not_null default  primary_key\n",
      "0      0           store_id     TEXT         0    None            0\n",
      "1      1  external_store_id     TEXT         0    None            0\n",
      "2      2               name     TEXT         0    None            0\n",
      "3      3             active     TEXT         0    None            0\n",
      "4      4         created_at     TEXT         0    None            0\n",
      "5      5         updated_at     TEXT         0    None            0\n",
      "6      6       delivery_fee     TEXT         0    None            0\n",
      "7      7       platform_fee     TEXT         0    None            0\n",
      "8      8       consumer_fee     TEXT         0    None            0\n",
      "9      9           pre_sale     TEXT         0    None            0\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "db_path = \"Processed/dashboard_chatbot.db\"\n",
    "conn = sqlite3.connect(db_path)\n",
    "\n",
    "# 1) Get the list of tables\n",
    "tables = pd.read_sql_query(\n",
    "    \"SELECT name FROM sqlite_master WHERE type='table';\",\n",
    "    conn\n",
    ")\n",
    "print(\"Tables in database:\", tables['name'].tolist())\n",
    "\n",
    "# 2) For each table, use PRAGMA table_info(...)\n",
    "def describe_table(table_name):\n",
    "    df = pd.read_sql_query(f\"PRAGMA table_info({table_name});\", conn)\n",
    "    df = df.rename(columns={\n",
    "        'cid': 'index',\n",
    "        'name': 'column',\n",
    "        'type': 'datatype',\n",
    "        'notnull': 'not_null',\n",
    "        'dflt_value': 'default',\n",
    "        'pk': 'primary_key'\n",
    "    })\n",
    "    return df\n",
    "\n",
    "print(\"\\n-- orders schema --\")\n",
    "print(describe_table(\"orders\"))\n",
    "\n",
    "print(\"\\n-- customers schema --\")\n",
    "print(describe_table(\"customers\"))\n",
    "\n",
    "print(\"\\n-- stores schema --\")\n",
    "print(describe_table(\"stores\"))\n",
    "\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12241c90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "isat-demo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
